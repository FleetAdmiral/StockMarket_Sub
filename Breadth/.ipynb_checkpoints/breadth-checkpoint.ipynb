{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A3o2BbNnZ78f",
    "outputId": "9e0c15fc-0da4-4d93-e388-53671e86a27d"
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChUWeK2mZ78d"
   },
   "source": [
    "## Dataset\n",
    "There are two different kinds of data available.\n",
    "\n",
    "It is entirely up to you which set of data you work with, you may experiment with both\n",
    "and choose one that produces the best results or you can use both if you wish.\n",
    "\n",
    "Each dataset has 2 types of information, prices and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8mzVB6GZ78u"
   },
   "outputs": [],
   "source": [
    "mongo_client = pymongo.MongoClient(\n",
    "'mongodb://mlcandidates:crackthecode@100.2.158.147:27017/')\n",
    "finDb = mongo_client['findata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4WgyHGcZ784"
   },
   "outputs": [],
   "source": [
    "intradayCollection = finDb['intraday']\n",
    "dailyCollection = finDb['day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-fIzHjrZ79A"
   },
   "source": [
    "1. Minute data where each row in the dataframe represents one minute (intradayCollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjN2-LRkZ79B"
   },
   "outputs": [],
   "source": [
    "# To get all of the symbols available in the collection\n",
    "all_unique_intraday_symbols = intradayCollection.distinct('Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNOuqOhQZ79N"
   },
   "outputs": [],
   "source": [
    "# To get data for a specific symbol\n",
    "msft_intraday_df = pd.DataFrame(list(intradayCollection.find({'Symbol': 'MSFT', 'close': {'$exists':True}})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NHwFwLhZ79T"
   },
   "outputs": [],
   "source": [
    "# To get data for all symbols\n",
    "# all_stocks_intraday_df = pd.DataFrame(list(intradayCollection.find({'close':{'$exists':True}})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2_dy-3Fmsaz"
   },
   "source": [
    "Selecting random symbols from the list. This block of code can be used to select one or multiple symbols at random from the list by changing the sample size (currently set at 50). Current analysis has only been done for 'MSFT' symbol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "0hwQS8kiZ79H",
    "outputId": "b92c72da-e509-4c03-ef57-be04716248b4"
   },
   "outputs": [],
   "source": [
    "print(len(all_unique_intraday_symbols))\n",
    "intraday_symbols_sample = random.sample(all_unique_intraday_symbols, 50)\n",
    "print(intraday_symbols_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxWbikaWAN2A"
   },
   "source": [
    "## Observing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEKcvLPJniFI"
   },
   "source": [
    "### Trivial and Statistical Analysis of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "POvTWzRAZ79X",
    "outputId": "0c1212e0-4a38-4ca1-dae6-3c20e219070b"
   },
   "outputs": [],
   "source": [
    "print(msft_intraday_df.shape)\n",
    "print(msft_intraday_df.head(10))\n",
    "print(msft_intraday_df.columns.values)\n",
    "\n",
    "print(msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3bTJtGmVnc35"
   },
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "colab_type": "code",
    "id": "aDouu033Z79i",
    "outputId": "37ae6b84-6c34-42ed-d07f-20d715ebde1c"
   },
   "outputs": [],
   "source": [
    "# box and whisker plots\n",
    "msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']].plot(kind='box', subplots=True, layout=(1,5), sharex=False, sharey=False)\n",
    "plt.show()\n",
    "msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']].hist()\n",
    "plt.show()\n",
    "scatter_matrix(msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1o5J42zhAZ76"
   },
   "source": [
    "## Evaluating Some Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "nRGqSNNSoLlr",
    "outputId": "66ba60d3-78c9-44d5-f04d-5a40c6dadd91"
   },
   "outputs": [],
   "source": [
    "#setting index as date\n",
    "df = msft_intraday_df\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "df.index = df['Date']\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df['close'], label='Close Price history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMs5qLNPAxek"
   },
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "id": "xB-Aajm-sGh2",
    "outputId": "aa6ba3ba-2975-49a0-e137-81bec0ce5668"
   },
   "outputs": [],
   "source": [
    "#creating dataframe with date and the target variable\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'close'])\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "     new_data['Date'][i] = data['Date'][i]\n",
    "     new_data['close'][i] = data['close'][i]\n",
    "\n",
    "# splitting into train and validation\n",
    "train = new_data[:7500]\n",
    "valid = new_data[7500:]\n",
    "\n",
    "# In the next step, we will create predictions for the validation set and check the RMSE using the actual values.\n",
    "# making predictions using Moving average\n",
    "preds = []\n",
    "for i in range(0,valid.shape[0]):\n",
    "    a = train['close'][len(train)-2048+i:].sum() + sum(preds)\n",
    "    b = a/2048\n",
    "    preds.append(b)\n",
    "\n",
    "# checking the results\n",
    "mse=np.mean(np.power((np.array(valid['close'])-preds),2))\n",
    "rms=np.sqrt(np.mean(np.power((np.array(valid['close'])-preds),2)))\n",
    "print(f\"MSE: {mse} RMS: {rms}\")\n",
    "\n",
    "valid.insert(2, 'Predictions', preds, True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train['close'])\n",
    "plt.plot(valid[['close', 'Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5T_PThpA14y"
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "id": "Ry_QtdUZzYBx",
    "outputId": "2d38109a-948e-4a84-fddf-e3963e14db76"
   },
   "outputs": [],
   "source": [
    "# splitting into train and validation\n",
    "train = msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']][:7500]\n",
    "valid = msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']][7500:]\n",
    "\n",
    "x_train = train.drop('close', axis=1)\n",
    "y_train = train['close']\n",
    "x_valid = valid.drop('close', axis=1)\n",
    "y_valid = valid['close']\n",
    "\n",
    "#implement linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "preds = model.predict(x_valid)\n",
    "\n",
    "# checking the results\n",
    "mse=np.mean(np.power((np.array(valid['close'])-preds),2))\n",
    "rms=np.sqrt(np.mean(np.power((np.array(valid['close'])-preds),2)))\n",
    "print(f\"MSE: {mse} RMS: {rms}\")\n",
    "\n",
    "valid.insert(2, 'Predictions', preds, True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train['close'])\n",
    "plt.plot(valid[['close', 'Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9G3zuBxTA6Yq"
   },
   "source": [
    "### LSTM for Sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "VPbrq3FH4TY2",
    "outputId": "4f4d2a3d-423c-4f21-ed13-7f3a7f1829e4"
   },
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "data = data[['Date', 'close']]\n",
    "new_data = data.copy(deep = True)\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "train = dataset[0:7500,:]\n",
    "valid = dataset[7500:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYWQwUHlsoCI"
   },
   "source": [
    "#### Validation\n",
    "The number of prior datapoints used as input defines the one-dimensional (1D) subsequence of data that the LSTM will read and learn to extract features. We denote it here by `subsequence_length` which takes the past hour of data. We can also tune this hyperparameter using cross validation across multiple validatin datasets to arrive at an optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "otr-zeAJuiak",
    "outputId": "2f5d3e5a-612b-4779-9836-3510b993ae36"
   },
   "outputs": [],
   "source": [
    "subsequence_length = 60 #past one hour\n",
    "#predicting next values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - subsequence_length:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n",
    "# rms1 = np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "# print(rms1)\n",
    "mse=np.mean(np.power((np.array(valid) - closing_price),2))\n",
    "rms=np.sqrt(np.mean(np.power((np.array(valid) - closing_price),2)))\n",
    "print(f\"MSE: {mse} RMS: {rms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_nyHJp1sqzR"
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "gJQO2WXLumao",
    "outputId": "400cded8-5d9b-482d-8cf3-02ff5e12651e"
   },
   "outputs": [],
   "source": [
    "#for plotting\n",
    "training = new_data[:7500]\n",
    "validation = new_data[7500:]\n",
    "validation.insert(2, 'Predictions', closing_price, True)\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(training['close'])\n",
    "plt.plot(validation[['close','Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsHubUOwgUgf"
   },
   "source": [
    "### Multivariate LSTM for Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "pN8jDEtkBTDV",
    "outputId": "d2a6e5f7-5e69-46c7-91b1-231e454c5ad2"
   },
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "data = data[['Date', 'close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']]\n",
    "new_data = data.copy(deep = True)\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "# train = msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']][0:7500,:]\n",
    "# valid = msft_intraday_df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']][7500:,:]\n",
    "train = dataset[0:7500,:]\n",
    "valid = dataset[7500:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBJ4GszSsyG7"
   },
   "source": [
    "#### Validation\n",
    "The number of prior datapoints used as input defines the one-dimensional (1D) subsequence of data that the LSTM will read and learn to extract features. We denote it here by `subsequence_length` which takes the past hour of data. We can also tune this hyperparameter using cross validation across multiple validatin datasets to arrive at an optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "NroV80TgKJq0",
    "outputId": "630abdc8-0235-4ada-be79-31017d68648f"
   },
   "outputs": [],
   "source": [
    "subsequence_length = 60 #past one hour\n",
    "#predicting next values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - subsequence_length:].values\n",
    "inputs = inputs.reshape(-1,5)\n",
    "inputs  = scaler.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = np.concatenate((closing_price, np.zeros((closing_price.shape[0],4))), axis = 1)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n",
    "\n",
    "closing_price = closing_price[:,:1]\n",
    "# print(closing_price)\n",
    "# print(valid[:,:1])\n",
    "mse=np.mean(np.power((np.array(valid[:,:1]) - closing_price),2))\n",
    "rms=np.sqrt(np.mean(np.power((np.array(valid[:,:1]) - closing_price),2)))\n",
    "print(f\"MSE: {mse} RMS: {rms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIUWSqdTs0bu"
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "id": "K4FIi8kZZsUH",
    "outputId": "d30808c0-887f-4306-ef88-137aa247aa18"
   },
   "outputs": [],
   "source": [
    "training = new_data[['close']][:7500]\n",
    "validation = new_data[['close']][7500:]\n",
    "validation.insert(2, 'Predictions', closing_price, True)\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(training['close'])\n",
    "plt.plot(validation[['close','Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4FcQXv7gjJ8"
   },
   "source": [
    "### Multivariate LSTM with seq2seq (Encoder-Decoder LSTM) (*Not Working, Disregard*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qZhGMyPcrWVE",
    "outputId": "e871e966-75f7-4285-f4a0-da6f4c91f0f1"
   },
   "outputs": [],
   "source": [
    "dataset = df[['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']].copy(deep = True)\n",
    "dataset = dataset[:(df.shape[0]-(df.shape[0]%10))]\n",
    "# dataset.drop('Date', inplace=True, axis=1)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "7pKYSze82BbF",
    "outputId": "35d0f8db-de3c-4614-8fc8-ad05dab81c45"
   },
   "outputs": [],
   "source": [
    "# split into standard weeks\n",
    "train, test = dataset.values[0:7500], dataset.values[7500:]\n",
    "\n",
    "# restructure into windows of weekly data\n",
    "# print(train.shape) # (750, 10, 5)\n",
    "train = np.array(np.split(train, len(train)/10))\n",
    "# print(test.shape)\n",
    "test = np.array(np.split(test, len(test)/10))\n",
    "\n",
    "n_input = 10\n",
    "\n",
    "# prepare data\n",
    "n_out=1\n",
    "# flatten data\n",
    "data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "print(data)\n",
    "print(data.shape)\n",
    "print(train.shape)\n",
    "X, y = list(), list()\n",
    "in_start = 0\n",
    "# step over the entire history one time step at a time\n",
    "for _ in range(len(data)):\n",
    "  # define the end of the input sequence\n",
    "  in_end = in_start + n_input\n",
    "  out_end = in_end + n_out\n",
    "  # ensure we have enough data for this instance\n",
    "  if out_end < len(data):\n",
    "    # print(len(data))\n",
    "    X.append(data[in_start:in_end, :])\n",
    "    y.append(data[in_end:out_end, 0])\n",
    "  # move along one time step\n",
    "  in_start += 1\n",
    "# print(np.array(X).shape)\n",
    "train_x, train_y = np.array(X), np.array(y)\n",
    "(750, 10, 5)\n",
    "# define parameters\n",
    "epochs, batch_size = 50, 60\n",
    "n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "# reshape output into [samples, timesteps, features]\n",
    "train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(RepeatVector(n_outputs))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit network\n",
    "model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsXO-Izes5Gf"
   },
   "outputs": [],
   "source": [
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "  # flatten data\n",
    "  data = np.array(history)\n",
    "  data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "  # retrieve last observations for input data\n",
    "  input_x = data[-n_input:, :]\n",
    "  input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "  yhat = model.predict(input_x, verbose=0)\n",
    "  # we only want the vector forecast\n",
    "  yhat_sequence = yhat[0]\n",
    "  # store the predictions\n",
    "  predictions.append(yhat_sequence)\n",
    "  # get real observation and add to history for predicting the next minute\n",
    "  history.append(test[i, :])\n",
    "predictions = np.array(predictions)\n",
    "actual = test[:, :, 0]\n",
    "\n",
    "mse=np.mean(np.power((np.array(actual) - predictions),2))\n",
    "rms=np.sqrt(np.mean(np.power((np.array(actual) - predictions),2)))\n",
    "print(f\"MSE: {mse} RMS: {rms}\")\n",
    "\n",
    "predictions = predictions.reshape((predictions.shape[0],1))\n",
    "\n",
    "training = dataset[['close']][:7500 ]\n",
    "validation = dataset[['close']][-len(predictions):]\n",
    "validation['Predictions'] = predictions\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(training['close'])\n",
    "plt.plot(validation[['close','Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w90KcG4NZ79z"
   },
   "outputs": [],
   "source": [
    "%time test_intraday_df = pd.DataFrame(list(intradayCollection.find({'Symbol': { '$in': intraday_symbols_sample}, 'close': {'$exists':True}})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEtLkFqOB7MY"
   },
   "outputs": [],
   "source": [
    "test_intraday_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqNHlc_TZ794"
   },
   "source": [
    "datapoints: ['close', 'volume', 'trending_score', 'sentiment_change', 'volume_change']\n",
    "the goal is to predict the 'close' using any combination of the other data points.\n",
    "\n",
    "\n",
    "2. Daily data where each row in the dataframe represents one day (dailyCollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSoTVzc1Z795"
   },
   "outputs": [],
   "source": [
    "# To get all of the symbols available in the collection\n",
    "all_unique_daily_symbols = dailyCollection.distinct('Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJJA4lFeZ79-"
   },
   "outputs": [],
   "source": [
    "print(len(all_unique_daily_symbols))\n",
    "daily_symbols_sample = random.sample(all_unique_daily_symbols, 300)\n",
    "print(daily_symbols_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTCjb7i9Z7-D"
   },
   "outputs": [],
   "source": [
    "# To get data for a specific symbol\n",
    "%time msft_daily_df = pd.DataFrame(list(dailyCollection.find({'Symbol': 'MSFT', 'close': {'$ne': 'NaN'}})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btRwqLeRZ7-G"
   },
   "outputs": [],
   "source": [
    "len(all_unique_daily_symbols)\n",
    "print(msft_daily_df.shape)\n",
    "\n",
    "print(msft_intraday_df.columns.values)\n",
    "msft_daily_df[['Close', 'Volume', 'volume_change', 'volume_score', 'bullish', 'bearish']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HGo8bqnZ7-M"
   },
   "outputs": [],
   "source": [
    "all_stocks_daily_df = pd.DataFrame(list(dailyCollection.find({'close':{'$ne':'NaN'}})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIVKb7OPZ7-P"
   },
   "source": [
    "datapoints: ['Close', 'Volume', 'volume_change', 'volume_score', 'bullish', 'bearish']\n",
    "the goal is to predict the 'Close' using any combination of the other data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "soultion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
